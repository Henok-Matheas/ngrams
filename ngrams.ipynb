{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Henok-Matheas/ngrams/blob/main/ngrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "f_de8rc-Y6a2"
      },
      "outputs": [],
      "source": [
        "corpus_file = \"/content/GPAC.txt\"\n",
        "\n",
        "with open(corpus_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    corpus_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xRwT-cubiag",
        "outputId": "66bc5189-5476-4b1a-899d-f9cec7c0b9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download(\"punkt\")\n",
        "from nltk import ngrams\n",
        "from nltk.probability import FreqDist, ConditionalFreqDist, ConditionalProbDist\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(text, pad_size = 0, pad_symbol = ''):\n",
        "  stopwords_file = \"/content/stopwords.txt\"\n",
        "\n",
        "  with open(stopwords_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "      stopwords = f.read()\n",
        "\n",
        "\n",
        "  # Remove punctuation\n",
        "  text = re.sub('[\\!\\@\\#\\$\\%\\^\\«\\»\\&\\*\\(\\)\\…\\[\\]\\{\\}\\;\\“\\”\\›\\’\\‘\\\"\\'\\:\\,\\.\\‹\\/\\<\\>\\?\\\\\\\\|\\`\\´\\~\\-\\=\\+\\፡\\፤\\;\\፦\\፥\\፧\\፨\\፠\\፣]', '', text)\n",
        "\n",
        "  # change \\። with padding\n",
        "  padding = (\" \" + pad_symbol + \" \") * pad_size\n",
        "  text = re.sub('\\።', padding if padding else \"\", text)\n",
        "\n",
        "  # Tokenize the text into words\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  # Remove stopwords\n",
        "  stop_words = set(stopwords)\n",
        "  tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "S10u3LX5jFtg"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ngram(tokens, gram_size, pad_symbol, pad_size):\n",
        "  return list(ngrams(list(nltk.pad_sequence(tokens, pad_size, pad_left=True, pad_right=True, left_pad_symbol=pad_symbol, right_pad_symbol=pad_symbol)), gram_size))"
      ],
      "metadata": {
        "id": "nnTjU1NRojof"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.6\n",
        "\n",
        "unigram_total_tokens = pre_process(corpus_text)\n",
        "unigram_tokens, unigram_test_tokens = unigram_total_tokens[:int(len(unigram_total_tokens) * test_size)], unigram_total_tokens[int(len(unigram_total_tokens) * test_size):]\n",
        "unigrams = create_ngram(unigram_tokens, 1, \"<PAD>\", 1)\n",
        "print(unigrams[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hVSzLHAqs-O",
        "outputId": "c9fd28c7-799e-46e1-c28a-248ef6d48b40"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ምን', 'መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ']\n",
            "[('ምን',), ('መሰላችሁ',), ('አንባቢያን',), ('ኢትዮጵያ',), ('በተደጋጋሚ',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_total_tokens = pre_process(corpus_text, 1, \"<PAD>\")\n",
        "bigram_tokens, bigram_test_tokens = bigram_total_tokens[:int(len(bigram_total_tokens) * test_size)], bigram_total_tokens[int(len(bigram_total_tokens) * test_size):]\n",
        "bigrams = create_ngram(bigram_tokens, 2, \"<PAD>\", 1)\n",
        "print(bigrams[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0q4-NPqri7Q",
        "outputId": "42582453-9027-4445-8dcc-12dc6b1c5ea4"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ምን', 'መሰላችሁ'), ('መሰላችሁ', 'አንባቢያን'), ('አንባቢያን', 'ኢትዮጵያ'), ('ኢትዮጵያ', 'በተደጋጋሚ'), ('በተደጋጋሚ', 'ጥሪው')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_total_tokens = pre_process(corpus_text, 2, \"<PAD>\")\n",
        "trigram_tokens, trigram_test_tokens = trigram_total_tokens[:int(len(trigram_total_tokens) * test_size)], trigram_total_tokens[int(len(trigram_total_tokens) * test_size):]\n",
        "trigrams = create_ngram(trigram_tokens, 3, \"<PAD>\", 1)\n",
        "print(trigrams[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXCluPXYthmi",
        "outputId": "883f2c0b-07b0-413a-f67b-6cdf79cfc123"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ምን', 'መሰላችሁ', 'አንባቢያን'), ('መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ'), ('አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ'), ('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው'), ('በተደጋጋሚ', 'ጥሪው', 'ደርሷት')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fourgram_total_tokens = pre_process(corpus_text, 3, \"<PAD>\")\n",
        "fourgram_tokens, fourgram_test_tokens = fourgram_total_tokens[:int(len(fourgram_total_tokens) * test_size)], fourgram_total_tokens[int(len(fourgram_total_tokens) * test_size):]\n",
        "fourgrams = create_ngram(fourgram_tokens, 4, \"<PAD>\", 1)\n",
        "print(fourgrams[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRU_UXzZtPJ3",
        "outputId": "b007104b-b905-40fb-9c76-0191bfb9e02b"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ምን', 'መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ'), ('መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ'), ('አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው'), ('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው', 'ደርሷት'), ('በተደጋጋሚ', 'ጥሪው', 'ደርሷት', 'ልትታደመው')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def top_n_frequent(ngrams, top_n):\n",
        "  # Calculate counts\n",
        "  ngram_counts = Counter(ngrams)\n",
        "\n",
        "  ngram_total_count = sum(ngram_counts.values())\n",
        "\n",
        "  ngram_probabilities = {gram: count / ngram_total_count for gram, count in ngram_counts.items()}\n",
        "\n",
        "  # return the n most frequent n-grams\n",
        "  return sorted(ngram_probabilities.items(), key=lambda x: x[1], reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "3sZvWxcotoIQ"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top 10 n-grams\n",
        "top_n = 10\n",
        "\n",
        "print(\"Top 10 Unigrams:\", top_n_frequent(unigrams, top_n))\n",
        "print(\"Top 10 Bigrams:\", top_n_frequent(bigrams, top_n))\n",
        "print(\"Top 10 Trigrams:\", top_n_frequent(trigrams, top_n))\n",
        "print(\"Top 10 Fourgrams:\", top_n_frequent(fourgrams, top_n))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_SoxYR4twK-",
        "outputId": "de04e03a-83cb-4194-dda9-da3a28e3eeee"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Unigrams: [(('ነው',), 0.017193487115863902), (('ላይ',), 0.009529978810070157), (('ነበር',), 0.0056433284658710375), (('ግን',), 0.005423743700662048), (('ወደ',), 0.005259055126755305), (('ውስጥ',), 0.004764989405035078), (('ጋር',), 0.004270923683314852), (('እና',), 0.004029380441584963), (('ነገር',), 0.0038866503441991195), (('እንደ',), 0.0032827922398743973)]\n",
            "Top 10 Bigrams: [(('ነገር', 'ግን'), 0.0007795344751866491), (('ብቻ', 'ሳይሆን'), 0.0006038647342995169), (('ማለት', 'ነው'), 0.0005928853754940712), (('ብቻ', 'ነው'), 0.0005379885814668423), (('ናርኮ', 'ጋንጐች'), 0.0003952569169960474), (('ኢብን', 'ባቱታ'), 0.0003184014053579271), (('ወደ', 'ኋላ'), 0.0002964426877470356), (('አዲስ', 'አበባ'), 0.0002854633289415898), (('በስድስት', 'ወር'), 0.0002854633289415898), (('አንድ', 'ቀን'), 0.00027448397013614406)]\n",
            "Top 10 Trigrams: [(('ሀሁ', 'በስድስት', 'ወር'), 0.00021958958706178153), (('ሀሁ', 'ወይም', 'ፐፑ'), 0.00016469219029633614), (('ያም', 'ሆነ', 'ይህ'), 0.00012077427288397984), (('ጋር', 'ሆኖ', 'ኢህአዴግን'), 0.00010979479353089076), (('ሆኖ', 'ኢህአዴግን', 'ወጋ'), 0.00010979479353089076), (('ከኢህአዴግ', 'ጋር', 'ሆኖ'), 0.00010979479353089076), (('በብርሃንና', 'ሰላም', 'ማተሚያ'), 0.00010979479353089076), (('ሰላም', 'ማተሚያ', 'ቤት'), 0.00010979479353089076), (('እናት', 'ዓለም', 'ጠኑ'), 0.00010979479353089076), (('ከፖለቲካ', 'ያገኛቸው', 'ክብር'), 8.783583482471262e-05)]\n",
            "Top 10 Fourgrams: [(('ጋር', 'ሆኖ', 'ኢህአዴግን', 'ወጋ'), 0.00010979599903379521), (('በብርሃንና', 'ሰላም', 'ማተሚያ', 'ቤት'), 0.00010979599903379521), (('ከፖለቲካ', 'ያገኛቸው', 'ክብር', 'ተሰሚነት'), 8.783679922703617e-05), (('ጠቅላይ', 'ሚኒስትር', 'ናኦቶ', 'ካን'), 6.587759942027712e-05), (('ገብረአብ', 'እንደጠቢቡ', 'ሰሎሞን', 'በልጅነቱ'), 5.4897999516897606e-05), (('እንደጠቢቡ', 'ሰሎሞን', 'በልጅነቱ', 'አንጋፋው'), 5.4897999516897606e-05), (('ሰሎሞን', 'በልጅነቱ', 'አንጋፋው', 'ፕሬስ'), 5.4897999516897606e-05), (('በልጅነቱ', 'አንጋፋው', 'ፕሬስ', 'ድርጅት'), 5.4897999516897606e-05), (('አንጋፋው', 'ፕሬስ', 'ድርጅት', 'ላይ'), 5.4897999516897606e-05), (('ፕሬስ', 'ድርጅት', 'ላይ', 'ሲነግስ'), 5.4897999516897606e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(ngrams, n = 1):\n",
        "  # Create conditional frequency distribution for n-grams\n",
        "  dist_list = []\n",
        "  for words in ngrams:\n",
        "    if n == 1:\n",
        "      dist_list.append(list(words)[0])\n",
        "    elif n == 2:\n",
        "      dist_list.append((list(words)[0], words[-1]))\n",
        "    else:\n",
        "      dist_list.append((tuple(list(words[:-1])), words[-1]))\n",
        "\n",
        "  if n == 1:\n",
        "    return FreqDist(dist_list)\n",
        "\n",
        "  # Calculate the conditional probability of each n-gram\n",
        "  return nltk.ConditionalProbDist(ConditionalFreqDist(dist_list), nltk.MLEProbDist)"
      ],
      "metadata": {
        "id": "9x-I3D4swCnM"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create models\n",
        "unigram_model = create_model(unigrams)\n",
        "bigram_model = create_model(bigrams, n = 2)\n",
        "trigram_model = create_model(trigrams, n = 3)\n",
        "fourgram_model = create_model(fourgrams, n = 4)"
      ],
      "metadata": {
        "id": "gou4od6uwKex"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_probability(model, sentence_ngram, n = 1):\n",
        "  probability = 1.0\n",
        "  total = None if n > 1 else model.N()\n",
        "\n",
        "  for words in sentence_ngram:\n",
        "      if n < 3:\n",
        "        condition = list(words)[0]\n",
        "      else:\n",
        "        condition = tuple(list(words)[:-1])\n",
        "\n",
        "      event = words[-1] if n > 1 else None\n",
        "      if n > 1:\n",
        "        word_probability = model[condition].prob(event)\n",
        "      else:\n",
        "        word_probability = model[condition] / total\n",
        "      probability *= word_probability\n",
        "\n",
        "  return probability"
      ],
      "metadata": {
        "id": "rSyPwQ5-ucow"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"ጋር ሆኖ ኢህአዴግን ወጋ\"\n",
        "\n",
        "sentence_unigram_tokens = pre_process(sentence)\n",
        "sentence_unigrams = create_ngram(sentence_unigram_tokens, 1, \"<PAD>\", 1)\n",
        "\n",
        "sentence_bigram_tokens = pre_process(sentence, 1, \"<PAD>\")\n",
        "sentence_bigrams = create_ngram(sentence_bigram_tokens, 2, \"<PAD>\", 1)\n",
        "\n",
        "sentence_trigram_tokens = pre_process(sentence, 2, \"<PAD>\")\n",
        "sentence_trigrams = create_ngram(sentence_trigram_tokens, 3, \"<PAD>\", 1)\n",
        "\n",
        "sentence_fourgram_tokens = pre_process(sentence, 3, \"<PAD>\")\n",
        "sentence_fourgrams = create_ngram(sentence_fourgram_tokens, 4, \"<PAD>\", 1)"
      ],
      "metadata": {
        "id": "fGFfvRBZz1zA"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_probability = find_probability(unigram_model, sentence_unigrams)\n",
        "bigram_probability = find_probability(bigram_model, sentence_bigrams, 2)\n",
        "trigram_probability = find_probability(trigram_model, sentence_trigrams, 3)\n",
        "fourgram_probability = find_probability(fourgram_model, sentence_fourgrams, 4)\n",
        "\n",
        "print(\"Unigram Probability:\", unigram_probability)\n",
        "print(\"Bigram Probability:\", bigram_probability)\n",
        "print(\"Trigram Probability:\", trigram_probability)\n",
        "print(\"Fourgram Probability:\", fourgram_probability)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwP8AW0w74Pi",
        "outputId": "59786d32-0d74-4dd5-8209-7710b2691cef"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Probability: 1.6539133866028692e-13\n",
            "Bigram Probability: 0.004392847039308952\n",
            "Trigram Probability: 0.4\n",
            "Fourgram Probability: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_sentence(ngram_models, start_words = None, word_size = 100, n = 1):\n",
        "    sentences = []\n",
        "    while word_size:\n",
        "      if n == 1:\n",
        "        start_word = random.choice(list(ngram_models.keys()))\n",
        "        sentences.append(start_word)\n",
        "\n",
        "      elif start_words is None:\n",
        "          if n == 2:\n",
        "            start_words = random.choice(list(ngram_models.conditions()))\n",
        "            sentences.append(start_words)\n",
        "          else:\n",
        "            start_words = list(random.choice(list(ngram_models.conditions())))\n",
        "            sentences.extend(start_words)\n",
        "      else:\n",
        "          if n == 2:\n",
        "              cpd = ngram_models[start_words]\n",
        "          else:\n",
        "            cpd = ngram_models[tuple(start_words)]\n",
        "\n",
        "          if cpd is None:\n",
        "              break\n",
        "          next_word = cpd.generate()\n",
        "          if next_word is None:\n",
        "              break\n",
        "          sentences.append(next_word)\n",
        "          start_words = sentences[-(n-1):] if n != 2 else sentences[-1]\n",
        "\n",
        "      word_size -= 1\n",
        "\n",
        "\n",
        "    return \" \".join(sentences)\n"
      ],
      "metadata": {
        "id": "1WKx2INqpvdK"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As n increases the content of the generates sentences make more and more sense, this is due to having more of a history to work with."
      ],
      "metadata": {
        "id": "2NU1yu4mEe1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_generated_sentence = generate_sentence(unigram_model, start_words = None, word_size = 10, n = 1)\n",
        "bigram_generated_sentence = generate_sentence(bigram_model, start_words = None, word_size = 20, n = 2)\n",
        "trigram_generated_sentence = generate_sentence(trigram_model, start_words = None, word_size = 20, n = 3)\n",
        "fourgram_generated_sentence = generate_sentence(fourgram_model, start_words = None, word_size = 20, n = 4)\n",
        "\n",
        "\n",
        "print(\"Unigram Generated sentence:\", unigram_generated_sentence)\n",
        "print(\"Bigram Generated sentence:\", bigram_generated_sentence)\n",
        "print(\"Trigram Generated sentence:\", trigram_generated_sentence)\n",
        "print(\"Fourgram Generated sentence:\", fourgram_generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWNQsKpCz6Kk",
        "outputId": "1f2b55b3-1182-4f62-c2f5-228f5600fa3c"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Generated sentence: እንደጻፈው ተቀምጧልኢጣሊያዊ ግጥሚያም በዘመናት ሞኝነት የሳሚን እያንቀላፋ አምቆ ሮገር ይደርስ\n",
            "Bigram Generated sentence: ከሚጠቀሱባቸው ምሳሌያዊ አነጋገር መነሻ ጥያቄዎቹን ሥርዓት አምነው የተጠመቁ መንግሥታትም ዋነኛ መልእክታቸው የተሸከምነውን አድገን ተምረንና ስራ እንዳላከናወነ እንዲሰማቸው ሊያደርግ ይችላል የሚል\n",
            "Trigram Generated sentence: ጥላው የዚያ የራስህን መልክ ይዞ በሚያንፀባርቅ ነገር ላይ ትልከሰከሳለህ እንዴ የአህያ ስጋ አልጋ ሲሉት አመድ አቶ ያየህ ጥናቱን በተሰጠው ጊዜ ውስጥ\n",
            "Fourgram Generated sentence: ህልም ከችላ ባይነት ከስንፍና ወይም ከፍላጐተ ቢስነት አይፈጠርም የስኬታማ ሰዎች ሌላው መርህ ለመሥራት ፈቃደኛ መሆን ነው አንድ ድንቅ የሆነ ነገር ለመፍጠር ሁሌም\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate these Language Models Using Intrinsic Evaluation Method**"
      ],
      "metadata": {
        "id": "kKXb_eUkLMHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def calculate_perplexity(ngram_model, test_tokens, n):\n",
        "    total_probability = 0\n",
        "    total = len(test_tokens)\n",
        "\n",
        "    for idx in range(total - n + 1):\n",
        "        if n == 2:\n",
        "          condition = list(test_tokens[idx: idx + n - 1])[0]\n",
        "        else:\n",
        "          condition = tuple(test_tokens[idx: idx + n - 1])\n",
        "\n",
        "        event = test_tokens[idx + n - 1]\n",
        "        if n > 1:\n",
        "          probability = math.log(ngram_model[condition].prob(event)) if ngram_model[condition].prob(event) > 0 else 1 / total\n",
        "        else:\n",
        "          probability = math.log(ngram_model[event] / total) if ngram_model[event] > 0 else 1 / total\n",
        "        total_probability -= probability\n",
        "\n",
        "    return math.exp(total_probability / total)"
      ],
      "metadata": {
        "id": "_h1MTB3bLRYF"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unigram Perplexity: \", calculate_perplexity(unigram_model, unigram_test_tokens, 1))\n",
        "print(\"Bigram Perplexity: \", calculate_perplexity(bigram_model, bigram_test_tokens, 2))\n",
        "print(\"Trigram Perplexity: \", calculate_perplexity(trigram_model, trigram_test_tokens, 3))\n",
        "print(\"Fourgram Perplexity: \", calculate_perplexity(fourgram_model, fourgram_test_tokens, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f3PhP1APM2v",
        "outputId": "262c7ba9-1139-41f9-bf5a-64c2e6bcaa95"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Perplexity:  277.9982302804208\n",
            "Bigram Perplexity:  1.3341067891325795\n",
            "Trigram Perplexity:  1.0057939456694318\n",
            "Fourgram Perplexity:  1.0001197066987138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate these Language Models Using Extrinsic Evaluation Method**"
      ],
      "metadata": {
        "id": "ZgVQV3f_TAXi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0NSlYlqTC9d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeVlV/AEXWGL1vl4QxzwmX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}